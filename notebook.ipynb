{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bMBTVgeE0LLD"
      },
      "source": [
        "# Projeto 2 RI\n",
        "<h2>Gonçalo Silva - 103668<br/>\n",
        "Guilherme Antunes - 103600</h2>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SPE3498K1Nl7"
      },
      "source": [
        "## Install Requirements"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hq-43_1bDlPt",
        "outputId": "8cddc48b-22e5-47c3-fff3-06313141c32d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch in ./venv/lib/python3.10/site-packages (2.2.0)\n",
            "Requirement already satisfied: transformers in ./venv/lib/python3.10/site-packages (4.37.2)\n",
            "Requirement already satisfied: ranx in ./venv/lib/python3.10/site-packages (0.3.19)\n",
            "Requirement already satisfied: accelerate in ./venv/lib/python3.10/site-packages (0.26.1)\n",
            "Requirement already satisfied: fsspec in ./venv/lib/python3.10/site-packages (from torch) (2023.12.2)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in ./venv/lib/python3.10/site-packages (from torch) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in ./venv/lib/python3.10/site-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: sympy in ./venv/lib/python3.10/site-packages (from torch) (1.12)\n",
            "Requirement already satisfied: filelock in ./venv/lib/python3.10/site-packages (from torch) (3.13.1)\n",
            "Requirement already satisfied: jinja2 in ./venv/lib/python3.10/site-packages (from torch) (3.1.3)\n",
            "Requirement already satisfied: networkx in ./venv/lib/python3.10/site-packages (from torch) (3.2.1)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in ./venv/lib/python3.10/site-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in ./venv/lib/python3.10/site-packages (from torch) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in ./venv/lib/python3.10/site-packages (from torch) (11.4.5.107)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in ./venv/lib/python3.10/site-packages (from torch) (4.9.0)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in ./venv/lib/python3.10/site-packages (from torch) (2.19.3)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in ./venv/lib/python3.10/site-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in ./venv/lib/python3.10/site-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in ./venv/lib/python3.10/site-packages (from torch) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in ./venv/lib/python3.10/site-packages (from torch) (12.1.0.106)\n",
            "Requirement already satisfied: triton==2.2.0 in ./venv/lib/python3.10/site-packages (from torch) (2.2.0)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in ./venv/lib/python3.10/site-packages (from torch) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in ./venv/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.3.101)\n",
            "Requirement already satisfied: tqdm>=4.27 in ./venv/lib/python3.10/site-packages (from transformers) (4.66.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in ./venv/lib/python3.10/site-packages (from transformers) (0.20.3)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in ./venv/lib/python3.10/site-packages (from transformers) (0.15.1)\n",
            "Requirement already satisfied: numpy>=1.17 in ./venv/lib/python3.10/site-packages (from transformers) (1.26.3)\n",
            "Requirement already satisfied: requests in ./venv/lib/python3.10/site-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: packaging>=20.0 in ./venv/lib/python3.10/site-packages (from transformers) (23.2)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in ./venv/lib/python3.10/site-packages (from transformers) (0.4.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in ./venv/lib/python3.10/site-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in ./venv/lib/python3.10/site-packages (from transformers) (2023.12.25)\n",
            "Requirement already satisfied: fastparquet in ./venv/lib/python3.10/site-packages (from ranx) (2023.10.1)\n",
            "Requirement already satisfied: pandas in ./venv/lib/python3.10/site-packages (from ranx) (2.2.0)\n",
            "Requirement already satisfied: scipy>=1.8.0 in ./venv/lib/python3.10/site-packages (from ranx) (1.12.0)\n",
            "Requirement already satisfied: lz4 in ./venv/lib/python3.10/site-packages (from ranx) (4.3.3)\n",
            "Requirement already satisfied: cbor2 in ./venv/lib/python3.10/site-packages (from ranx) (5.6.1)\n",
            "Requirement already satisfied: seaborn in ./venv/lib/python3.10/site-packages (from ranx) (0.13.2)\n",
            "Requirement already satisfied: numba>=0.54.1 in ./venv/lib/python3.10/site-packages (from ranx) (0.59.0)\n",
            "Requirement already satisfied: tabulate in ./venv/lib/python3.10/site-packages (from ranx) (0.9.0)\n",
            "Requirement already satisfied: rich in ./venv/lib/python3.10/site-packages (from ranx) (13.7.0)\n",
            "Requirement already satisfied: ir-datasets in ./venv/lib/python3.10/site-packages (from ranx) (0.5.5)\n",
            "Requirement already satisfied: orjson in ./venv/lib/python3.10/site-packages (from ranx) (3.9.13)\n",
            "Requirement already satisfied: psutil in ./venv/lib/python3.10/site-packages (from accelerate) (5.9.8)\n",
            "Requirement already satisfied: llvmlite<0.43,>=0.42.0dev0 in ./venv/lib/python3.10/site-packages (from numba>=0.54.1->ranx) (0.42.0)\n",
            "Requirement already satisfied: cramjam>=2.3 in ./venv/lib/python3.10/site-packages (from fastparquet->ranx) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2020.1 in ./venv/lib/python3.10/site-packages (from pandas->ranx) (2024.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in ./venv/lib/python3.10/site-packages (from pandas->ranx) (2.8.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in ./venv/lib/python3.10/site-packages (from pandas->ranx) (2023.4)\n",
            "Requirement already satisfied: lxml>=4.5.2 in ./venv/lib/python3.10/site-packages (from ir-datasets->ranx) (5.1.0)\n",
            "Requirement already satisfied: trec-car-tools>=2.5.4 in ./venv/lib/python3.10/site-packages (from ir-datasets->ranx) (2.6)\n",
            "Requirement already satisfied: warc3-wet>=0.2.3 in ./venv/lib/python3.10/site-packages (from ir-datasets->ranx) (0.2.3)\n",
            "Requirement already satisfied: unlzw3>=0.2.1 in ./venv/lib/python3.10/site-packages (from ir-datasets->ranx) (0.2.2)\n",
            "Requirement already satisfied: beautifulsoup4>=4.4.1 in ./venv/lib/python3.10/site-packages (from ir-datasets->ranx) (4.12.3)\n",
            "Requirement already satisfied: pyautocorpus>=0.1.1 in ./venv/lib/python3.10/site-packages (from ir-datasets->ranx) (0.1.12)\n",
            "Requirement already satisfied: warc3-wet-clueweb09>=0.2.5 in ./venv/lib/python3.10/site-packages (from ir-datasets->ranx) (0.2.5)\n",
            "Requirement already satisfied: ijson>=3.1.3 in ./venv/lib/python3.10/site-packages (from ir-datasets->ranx) (3.2.3)\n",
            "Requirement already satisfied: inscriptis>=2.2.0 in ./venv/lib/python3.10/site-packages (from ir-datasets->ranx) (2.4.0.1)\n",
            "Requirement already satisfied: zlib-state>=0.1.3 in ./venv/lib/python3.10/site-packages (from ir-datasets->ranx) (0.1.6)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in ./venv/lib/python3.10/site-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in ./venv/lib/python3.10/site-packages (from requests->transformers) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in ./venv/lib/python3.10/site-packages (from requests->transformers) (2.2.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in ./venv/lib/python3.10/site-packages (from requests->transformers) (2024.2.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in ./venv/lib/python3.10/site-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in ./venv/lib/python3.10/site-packages (from rich->ranx) (2.17.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in ./venv/lib/python3.10/site-packages (from rich->ranx) (3.0.0)\n",
            "Requirement already satisfied: matplotlib!=3.6.1,>=3.4 in ./venv/lib/python3.10/site-packages (from seaborn->ranx) (3.8.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in ./venv/lib/python3.10/site-packages (from sympy->torch) (1.3.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in ./venv/lib/python3.10/site-packages (from beautifulsoup4>=4.4.1->ir-datasets->ranx) (2.5)\n",
            "Requirement already satisfied: mdurl~=0.1 in ./venv/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich->ranx) (0.1.2)\n",
            "Requirement already satisfied: cycler>=0.10 in ./venv/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn->ranx) (0.12.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in ./venv/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn->ranx) (1.2.0)\n",
            "Requirement already satisfied: pillow>=8 in ./venv/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn->ranx) (10.2.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in ./venv/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn->ranx) (3.1.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in ./venv/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn->ranx) (1.4.5)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in ./venv/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn->ranx) (4.47.2)\n",
            "Requirement already satisfied: six>=1.5 in ./venv/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->ranx) (1.16.0)\n",
            "Requirement already satisfied: cbor>=1.0.0 in ./venv/lib/python3.10/site-packages (from trec-car-tools>=2.5.4->ir-datasets->ranx) (1.0.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install torch transformers ranx scipy==1.8.0 accelerate"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MEOcgFN6HCkJ"
      },
      "source": [
        "## Download and Unzip Files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lymKPZngdIX0",
        "outputId": "35f3580a-9f07-49d6-a616-bb3128dc5700"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Archive:  files.zip\n",
            "   creating: files/collections/\n",
            "  inflating: files/collections/pubmed_2022_small.jsonl  "
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "  inflating: files/collections/pubmed_2022_tiny.jsonl  \n",
            "   creating: files/dev/\n",
            "   creating: files/dev/questions_for_train/\n",
            "  inflating: files/dev/questions_for_train/question_tiny_gs.jsonl  \n",
            "  inflating: files/dev/questions_for_train/question_small_gs.jsonl  \n",
            "   creating: files/dev/results/\n",
            "  inflating: files/dev/results/worst_tiny_results.jsonl  \n",
            "  inflating: files/dev/results/small_results.jsonl  \n",
            "  inflating: files/dev/results/worst_small_results.jsonl  \n",
            "  inflating: files/dev/results/tiny_results.jsonl  \n",
            "   creating: files/dev/results_filtered/\n",
            "   creating: files/dev/questions/\n",
            "  inflating: files/dev/questions/question_E8B2_gs.jsonl  \n",
            "  inflating: files/dev/questions/question_E8B1_gs.jsonl  \n",
            "   creating: files/eval/\n",
            "   creating: files/eval/results/\n",
            "   creating: files/eval/results/enunciado/\n",
            "  inflating: files/eval/results/enunciado/BM25_tiny.jsonl  \n",
            "  inflating: files/eval/results/enunciado/BM25_small.jsonl  \n",
            "   creating: files/eval/results/b075k12/\n",
            "  inflating: files/eval/results/b075k12/BM25_tiny.jsonl  \n",
            "  inflating: files/eval/results/b075k12/BM25_small.jsonl  \n",
            "   creating: files/eval/set/\n",
            "  inflating: files/eval/set/question_small.jsonl  \n",
            "  inflating: files/eval/set/question_tiny.jsonl  \n",
            "   creating: files/training/\n",
            "  inflating: files/training/BM25_tiny.jsonl  \n",
            "  inflating: files/training/question_training.json  \n",
            "  inflating: files/training/worst_BM25_small.jsonl  \n",
            "  inflating: files/training/BM25_small.jsonl  \n",
            "  inflating: files/training/worst_BM25_tiny.jsonl  \n",
            "  inflating: files/training/RI_2023_training_data_wContents.jsonl  \n",
            "  inflating: trainer/__pycache__/ranker_trainer.cpython-310.pyc  \n",
            "replace trainer/__pycache__/data.cpython-310.pyc? [y]es, [n]o, [A]ll, [N]one, [r]ename: ^C\n"
          ]
        }
      ],
      "source": [
        "!wget \"https://uapt33090-my.sharepoint.com/:f:/g/personal/guilherme_antunes_ua_pt/EoSzQHtDyzVNrNrcAFEFMZIBbSPWe23aGIbf0c81WLh41w?e=Q4Vvbb&download=1\" -O files.zip\n",
        "!rm -r files\n",
        "!unzip files\n",
        "!rm files.zip\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Choose Collection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "6i-eAEorzC2A"
      },
      "outputs": [],
      "source": [
        "COLLECTION = \"tiny\"\n",
        "# COLLECTION = \"small\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U4fziZOfiUWn"
      },
      "source": [
        "## Mine Negative and Positive Examples for Train and Dev set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "Ar4WU9I-iTDM"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "neg_f = open(f\"files/training/worst_BM25_{COLLECTION}.jsonl\", \"r\")\n",
        "pos_f = open(f\"files/training/BM25_{COLLECTION}.jsonl\", \"r\")\n",
        "f = open(\"files/training/RI_2023_training_data_wContents.jsonl\", \"r\")\n",
        "\n",
        "train_set_pos = open(f\"files/training/training_set_pos_{COLLECTION}.jsonl\", \"w\")\n",
        "train_set_neg = open(f\"files/training/training_set_neg_{COLLECTION}.jsonl\", \"w\")\n",
        "\n",
        "for pos, neg, n_pos in zip(f, neg_f, pos_f):\n",
        "    pos_data = json.loads(pos)\n",
        "    neg_data = json.loads(neg)\n",
        "    n_pos_data = json.loads(n_pos)\n",
        "    query_id = pos_data[\"id\"]\n",
        "    pos_docs = [d[\"id\"] for d in pos_data[\"documents\"]]\n",
        "    neg_docs = [d[\"id\"] for d in neg_data[\"documents\"]]\n",
        "    n_pos_docs = n_pos_data[\"documents\"]\n",
        "    neg_docs.reverse()\n",
        "\n",
        "    if len(n_pos_docs) > 0:\n",
        "        first_doc_score = n_pos_docs[0][\"score\"]*0.9\n",
        "        for doc in n_pos_docs:\n",
        "            if doc[\"score\"] < first_doc_score:\n",
        "                break\n",
        "            pos_docs.append(doc[\"id\"])\n",
        "\n",
        "    if len(pos_docs) == 0 or len(neg_docs) == 0:\n",
        "        continue\n",
        "    elif len(pos_docs) < len(neg_docs):\n",
        "        train_set_pos.write(json.dumps({\"query_id\": query_id, \"pos_docs\": pos_docs, \"body\": pos_data[\"body\"]}) + \"\\n\")\n",
        "        pos_set = set(pos_docs)\n",
        "        neg_set = set(neg_docs)\n",
        "        neg_docs = list(neg_set - pos_set)\n",
        "        if len(neg_docs) > 0:\n",
        "            train_set_neg.write(json.dumps({\"query_id\": query_id, \"neg_docs\": neg_docs}) + \"\\n\")\n",
        "\n",
        "pos_f.close()\n",
        "neg_f.close()\n",
        "f.close()\n",
        "\n",
        "neg_f = open(f\"files/dev/results/worst_{COLLECTION}_results.jsonl\", \"r\")\n",
        "pos_f = open(f\"files/dev/results/{COLLECTION}_results.jsonl\", \"r\")\n",
        "f = open(f\"files/dev/questions_for_train/question_{COLLECTION}_gs.jsonl\", \"r\")\n",
        "\n",
        "for pos, neg, n_pos in zip(f, neg_f, pos_f):\n",
        "    pos_data = json.loads(pos)\n",
        "    neg_data = json.loads(neg)\n",
        "    n_pos_data = json.loads(n_pos)\n",
        "    query_id = pos_data[\"id\"]\n",
        "    pos_docs = pos_data[\"documents\"]\n",
        "    neg_docs = [d[\"id\"] for d in neg_data[\"documents\"]]\n",
        "    n_pos_docs = n_pos_data[\"documents\"]\n",
        "    neg_docs.reverse()\n",
        "\n",
        "    if len(n_pos_docs) > 0:\n",
        "        first_doc_score = n_pos_docs[0][\"score\"]*0.9\n",
        "        for doc in n_pos_docs:\n",
        "            if doc[\"score\"] < first_doc_score:\n",
        "                break\n",
        "            pos_docs.append(doc[\"id\"])\n",
        "\n",
        "    if len(pos_docs) == 0 or len(neg_docs) == 0:\n",
        "        continue\n",
        "    elif len(pos_docs) < len(neg_docs):\n",
        "        train_set_pos.write(json.dumps({\"query_id\": query_id, \"pos_docs\": pos_docs, \"body\": pos_data[\"query_text\"]}) + \"\\n\")\n",
        "        pos_set = set(pos_docs)\n",
        "        neg_set = set(neg_docs)\n",
        "        neg_docs = list(neg_set - pos_set)\n",
        "        if len(neg_docs) > 0:\n",
        "            train_set_neg.write(json.dumps({\"query_id\": query_id, \"neg_docs\": neg_docs}) + \"\\n\")\n",
        "\n",
        "pos_f.close()\n",
        "neg_f.close()\n",
        "f.close()\n",
        "\n",
        "train_set_pos.close()\n",
        "train_set_neg.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Merge Positive, Negative and Dev Docs for Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {},
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "training_set_with_pos = open(f\"files/training/RI_2023_training_data_wContents.jsonl\", \"r\")\n",
        "neg_f = open(f\"files/training/training_set_neg_{COLLECTION}.jsonl\", \"r\")\n",
        "pos_f = open(f\"files/training/training_set_pos_{COLLECTION}.jsonl\", \"r\")\n",
        "collection = open(f\"files/collections/pubmed_2022_{COLLECTION}.jsonl\", \"r\")\n",
        "dev_set = open(f\"files/dev/questions_for_train/question_{COLLECTION}_gs.jsonl\", \"r\")\n",
        "\n",
        "with open(f\"files/training/training_data_{COLLECTION}.jsonl\", \"w\") as f:\n",
        "    for line in training_set_with_pos:\n",
        "        data = json.loads(line)\n",
        "        documents = data[\"documents\"]\n",
        "        for doc in documents:\n",
        "            f.write(json.dumps(doc) + \"\\n\")\n",
        "\n",
        "    docs = set()\n",
        "    for line in neg_f:\n",
        "        data = json.loads(line)\n",
        "        docs.update(data[\"neg_docs\"])\n",
        "\n",
        "    for line in pos_f:\n",
        "        data = json.loads(line)\n",
        "        docs.update(data[\"pos_docs\"])\n",
        "\n",
        "    for line in dev_set:\n",
        "        data = json.loads(line)\n",
        "        docs.update(data[\"documents\"])\n",
        "    \n",
        "    for line in collection:\n",
        "        data = json.loads(line)\n",
        "        if data[\"id\"] in docs:\n",
        "            f.write(line)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Filter Dev Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "mkdir: cannot create directory ‘files/dev/results_filtered’: File exists\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
          ]
        }
      ],
      "source": [
        "!mkdir files/dev/results_filtered\n",
        "\n",
        "import json\n",
        "\n",
        "results = open(f\"files/dev/results/{COLLECTION}_results.jsonl\", \"r\")\n",
        "questions = open(f\"files/dev/questions_for_train/question_{COLLECTION}_gs.jsonl\", \"r\")\n",
        "\n",
        "with open(f\"files/dev/results_filtered/{COLLECTION}_results.jsonl\", \"w\") as f:\n",
        "    with open(f\"files/dev/questions_for_train/filtered_question_{COLLECTION}_gs.jsonl\", \"w\") as f2:\n",
        "        for r, q in zip(results, questions):\n",
        "            r_data = json.loads(r)\n",
        "            q_data = json.loads(q)\n",
        "            r_docs = {doc[\"id\"]: doc[\"score\"] for doc in r_data[\"documents\"]}\n",
        "            filtered_docs = []\n",
        "            for doc_id in q_data[\"documents\"]:\n",
        "                if doc_id in r_docs:\n",
        "                    filtered_docs.append({\"id\": doc_id, \"score\": r_docs[doc_id]})\n",
        "            if len(filtered_docs) > 0:\n",
        "                f.write(json.dumps({\"id\": r_data[\"id\"], \"documents\": filtered_docs, \"question\": r_data[\"question\"]}) + \"\\n\")\n",
        "                f2.write(json.dumps(q_data) + \"\\n\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Bert Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {},
      "outputs": [],
      "source": [
        "from trainer.data import InferenceRankingIterator,  BioASQPointwiseIterator, InferenceDataset, create_training_dataset\n",
        "from trainer.sampler import BasicSampler\n",
        "from transformers import AutoTokenizer\n",
        "\n",
        "model_checkpoint = \"bert-base-uncased\"\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
        "tokenizer.model_max_length = 512\n",
        "\n",
        "train_ds = create_training_dataset(\n",
        "    f\"files/training/training_set_pos_{COLLECTION}.jsonl\",\n",
        "    f\"files/training/training_set_neg_{COLLECTION}.jsonl\",\n",
        "    f\"files/training/training_data_{COLLECTION}.jsonl\",\n",
        "    tokenizer=tokenizer,\n",
        "    iterator_class=BioASQPointwiseIterator[BasicSampler],\n",
        ")\n",
        "\n",
        "dev_ds = InferenceDataset(f\"files/dev/results_filtered/{COLLECTION}_results.jsonl\",\n",
        "                          train_ds.collection,\n",
        "                          tokenizer,\n",
        "                          #max_questions=10, # debug\n",
        "                          at=100, # max_docs\n",
        "                          gs_path=f\"files/dev/questions_for_train/filtered_question_{COLLECTION}_gs.jsonl\",\n",
        "                          iterator_class=InferenceRankingIterator)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoModelForSequenceClassification\n",
        "\n",
        "id2label = {0: \"IRRELEVANT\", 1: \"RELEVANT\"}\n",
        "label2id = {\"IRRELEVANT\": 0, \"RELEVANT\": 1}\n",
        "\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    model_checkpoint, num_labels=2, id2label=id2label, label2id=label2id\n",
        ").to(\"cuda\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Token indices sequence length is longer than the specified maximum sequence length for this model (747 > 512). Running this sequence through the model will result in indexing errors\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'input_ids': [101, 2003, 1996, 6121, 3252, 1997, 14255, 2213, 1011, 1015, 2800, 1029, 102, 1037, 12379, 1011, 5250, 8382, 25776, 2817, 1997, 1996, 8031, 1997, 7920, 18595, 2819, 3375, 10099, 2000, 14255, 2213, 2487, 1010, 28177, 2243, 1011, 1017, 29720, 1010, 1998, 3729, 2243, 2475, 1013, 22330, 20464, 2378, 1037, 5250, 21903, 2015, 1012, 2057, 12666, 7241, 25776, 24710, 2000, 2839, 4697, 1996, 10266, 1997, 2048, 4372, 4630, 18994, 22420, 3596, 1997, 1037, 21766, 1011, 3375, 7328, 1006, 1015, 1011, 1054, 1998, 1015, 1011, 1055, 1007, 2007, 2093, 5250, 21903, 2015, 1010, 8419, 14255, 2213, 2487, 1010, 28177, 2243, 1011, 1017, 29720, 1010, 1998, 3729, 2243, 2475, 1013, 22330, 20464, 2378, 1037, 1012, 2057, 2265, 2008, 2256, 7241, 25776, 15078, 8778, 23613, 4275, 1996, 8332, 2838, 1997, 2122, 10266, 1998, 5860, 20026, 28184, 2090, 6637, 23758, 3370, 2389, 12906, 1997, 27854, 1011, 5391, 5250, 5090, 1012, 2478, 1996, 4340, 1060, 1011, 4097, 6121, 3252, 1997, 14255, 2213, 2487, 3375, 2098, 2000, 1996, 7328, 1015, 1011, 1054, 2004, 1037, 2491, 1010, 2057, 6848, 1996, 5197, 1997, 2164, 1996, 5250, 16991, 16112, 1999, 1996, 7241, 25776, 8778, 1010, 2005, 1996, 10640, 1997, 1996, 3252, 17547, 1997, 1996, 5391, 2110, 1012, 1037, 7831, 1997, 2256, 7241, 25776, 3463, 6083, 2008, 14255, 2213, 2487, 1998, 28177, 2243, 1011, 1017, 29720, 14187, 1996, 2048, 4372, 4630, 18994, 2545, 1999, 2714, 4827, 1010, 2083, 2048, 3078, 8031, 11583, 1024, 23758, 3370, 1045, 1010, 2029, 2003, 2200, 2714, 2000, 1996, 23758, 3370, 3591, 1999, 1996, 4493, 14255, 2213, 2487, 1013, 7328, 1015, 1011, 1054, 6121, 3252, 1025, 23758, 3370, 2462, 1010, 2029, 5836, 1037, 8380, 7737, 11238, 2055, 2019, 8123, 2083, 1996, 18699, 2177, 1997, 1996, 1052, 12541, 13820, 10010, 3676, 6844, 2571, 25175, 27405, 1010, 5816, 2000, 23758, 3370, 1045, 1012, 1999, 5688, 1010, 1996, 8031, 1997, 1996, 4372, 4630, 18994, 2545, 2000, 3729, 2243, 2475, 2003, 2179, 2000, 2031, 1037, 2367, 8332, 6337, 2164, 1037, 4081, 5391, 23758, 3370, 1010, 2029, 14087, 1996, 19995, 9732, 5416, 2090, 1996, 21903, 1998, 1996, 27854, 1006, 1045, 1012, 1041, 1012, 1010, 12649, 1010, 2358, 21159, 2891, 17822, 3170, 1010, 21766, 1011, 3375, 7328, 1007, 1012, 1996, 2327, 4577, 23758, 3370, 1997, 1996, 24054, 5391, 2000, 3729, 2243, 2475, 2003, 2025, 2556, 2426, 1996, 2327, 1011, 4577, 23758, 10708, 1997, 1996, 24054, 5391, 2000, 2593, 14255, 2213, 2487, 2030, 28177, 2243, 1011, 1017, 29720, 1998, 3580, 1011, 18601, 1012, 13643, 1010, 2256, 3463, 2393, 3073, 9593, 1011, 2504, 20062, 2046, 24054, 7276, 7730, 2426, 1996, 2093, 21903, 2015, 1012, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'label_ids': 1}\n",
            "{'input_ids': [101, 2054, 2024, 10381, 21716, 21821, 1029, 102, 23586, 1997, 18847, 19915, 23060, 8524, 3366, 2011, 3479, 1039, 2575, 1011, 17316, 10381, 21716, 5643, 16942, 1012, 10381, 21716, 5643, 2038, 2042, 2988, 2000, 2022, 1037, 6179, 8040, 10354, 10371, 2005, 1996, 2640, 1997, 18847, 19915, 23060, 8524, 3366, 1006, 15158, 1007, 25456, 1012, 1999, 2019, 3535, 2000, 7523, 3811, 16834, 15158, 25456, 1998, 2000, 9002, 2000, 1996, 2124, 3252, 1011, 4023, 6550, 1006, 18906, 1007, 1997, 15158, 23586, 2011, 10381, 21716, 21821, 1010, 1999, 1996, 2556, 2817, 1010, 2057, 2031, 23572, 1037, 2186, 1997, 10381, 21716, 5643, 16942, 17316, 2012, 1039, 2575, 2007, 1037, 3528, 1997, 2632, 4801, 4135, 18037, 4942, 16643, 8525, 11187, 1010, 1998, 16330, 1996, 4525, 10099, 2004, 25456, 1997, 28667, 5358, 21114, 3372, 2529, 15158, 1011, 1037, 1998, 1011, 1038, 1012, 1996, 3463, 6254, 2008, 1996, 1039, 2575, 1011, 17316, 10381, 21716, 21821, 2024, 16834, 7065, 2545, 7028, 15158, 1011, 1038, 25456, 2007, 24582, 1006, 2753, 1007, 5300, 1999, 1996, 2659, 13221, 2846, 1006, 1016, 1011, 6146, 13221, 1007, 1012, 1996, 10381, 21716, 21821, 2020, 2036, 2179, 2000, 14187, 7065, 2545, 17296, 2000, 15158, 1011, 1037, 1010, 2021, 2007, 2896, 21358, 16294, 6447, 4102, 2000, 15158, 1011, 1038, 1012, 2009, 2089, 3568, 2022, 5531, 2008, 1039, 2575, 1011, 17316, 10381, 21716, 21821, 2024, 3811, 16834, 15158, 1011, 1038, 13228, 25456, 1998, 10015, 2599, 10099, 2005, 1996, 2458, 1997, 7242, 2005, 11265, 10976, 3207, 6914, 25284, 10840, 2107, 2004, 20310, 1005, 1055, 4295, 1012, 1996, 3463, 1997, 2023, 2817, 2024, 6936, 2007, 4431, 2000, 2825, 8031, 10296, 2015, 1997, 1037, 3479, 1039, 2575, 1011, 17316, 10381, 21716, 5643, 1999, 1996, 3161, 2609, 6187, 5737, 7368, 1997, 15158, 1011, 1037, 1998, 1011, 1038, 1012, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'label_ids': 0}\n"
          ]
        }
      ],
      "source": [
        "_iter = iter(train_ds)\n",
        "\n",
        "print(next(_iter))\n",
        "print(next(_iter))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {},
      "outputs": [],
      "source": [
        "from transformers import TrainingArguments\n",
        "\n",
        "training_args = TrainingArguments(num_train_epochs=3,\n",
        "                                  learning_rate=2e-5, # AdamW\n",
        "                                  weight_decay=0.01,\n",
        "                                  per_device_train_batch_size=8,\n",
        "                                  per_device_eval_batch_size=32,\n",
        "                                  evaluation_strategy= \"epoch\",\n",
        "                                  dataloader_pin_memory=True,\n",
        "                                  output_dir=\"trained_model\",\n",
        "                                  logging_strategy=\"steps\",\n",
        "                                  logging_first_step=True,\n",
        "                                  logging_steps=100,\n",
        "                                  save_strategy=\"epoch\",\n",
        "                                  save_total_limit=3,\n",
        "                                  seed=42,\n",
        "                                  report_to=\"none\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {},
      "outputs": [],
      "source": [
        "from trainer.ranker_trainer import RankerTrainer\n",
        "from transformers import DataCollatorWithPadding\n",
        "from trainer.collator import RankingCollator\n",
        "from trainer.metrics import RanxMetrics\n",
        "\n",
        "import torch\n",
        "\n",
        "trainer = RankerTrainer(\n",
        "      model=model,\n",
        "      args=training_args,\n",
        "      train_dataset=train_ds,\n",
        "      eval_dataset=dev_ds, # validation set\n",
        "      tokenizer=tokenizer,\n",
        "      data_collator=DataCollatorWithPadding(tokenizer=tokenizer), # apply to train\n",
        "      eval_data_collator=RankingCollator(tokenizer=tokenizer), # apply to val\n",
        "      preprocess_logits_for_metrics=lambda logits, labels: torch.nn.functional.softmax(logits, dim=-1)[:,1], # prob for class 1 (relevant class)\n",
        "      compute_metrics=RanxMetrics(dev_ds.get_qrels()),\n",
        "  )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2' max='14595' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [    2/14595 : < :, Epoch 0.00/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[74], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/RI/venv/lib/python3.10/site-packages/transformers/trainer.py:1539\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1537\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1539\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1540\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1541\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1542\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1544\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/RI/venv/lib/python3.10/site-packages/transformers/trainer.py:1874\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   1868\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39maccumulate(model):\n\u001b[1;32m   1869\u001b[0m     tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining_step(model, inputs)\n\u001b[1;32m   1871\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   1872\u001b[0m     args\u001b[38;5;241m.\u001b[39mlogging_nan_inf_filter\n\u001b[1;32m   1873\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_tpu_available()\n\u001b[0;32m-> 1874\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39misnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43misinf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtr_loss_step\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1875\u001b[0m ):\n\u001b[1;32m   1876\u001b[0m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[1;32m   1877\u001b[0m     tr_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m tr_loss \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_globalstep_last_logged)\n\u001b[1;32m   1878\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!wget \"https://uapt33090-my.sharepoint.com/:f:/g/personal/guilherme_antunes_ua_pt/EvrXz1YADDpJqUjgzy0MCr0B-s3lQIvgg6T6CQdW36P1fg?e=CyjlRx&download=1\" -O files.zip\n",
        "!rm -r trained_model\n",
        "!unzip trained_model\n",
        "!rm trained_model.zip\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Test Bert Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {},
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "\n",
        "model_checkpoint = \"trained_model/checkpoint-2433\"\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
        "tokenizer.model_max_length = 512\n",
        "\n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_checkpoint).to(\"cuda\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {},
      "outputs": [],
      "source": [
        "from trainer.utils import load_collection_lookup\n",
        "from trainer.data import InferenceRankingIterator, InferenceDataset\n",
        "from trainer.collator import RankingCollator\n",
        "import torch\n",
        "from tqdm import tqdm\n",
        "\n",
        "# load the collection lookup\n",
        "collection = load_collection_lookup(f\"files/collections/pubmed_2022_{COLLECTION}.jsonl\")\n",
        "\n",
        "eval_ds = InferenceDataset(f\"files/eval/results/b075k12/BM25_{COLLECTION}.jsonl\",\n",
        "                            collection,\n",
        "                            tokenizer,\n",
        "                            at=100, #max docs pq q\n",
        "                            iterator_class=InferenceRankingIterator)\n",
        "\n",
        "dataloader = torch.utils.data.DataLoader(eval_ds,\n",
        "                                         batch_size=32,\n",
        "                                         pin_memory=True,\n",
        "                                         collate_fn=RankingCollator(tokenizer))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "torch.Size([32, 512])"
            ]
          },
          "execution_count": 79,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "_sample = next(iter(dataloader))\n",
        "\n",
        "_sample[\"inputs\"].input_ids.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/310 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 1/310 [02:34<13:17:27, 154.85s/it]\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[80], line 19\u001b[0m\n\u001b[1;32m     15\u001b[0m   \u001b[38;5;66;03m# 32,\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, q_id \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(sample[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m\"\u001b[39m]):\n\u001b[1;32m     18\u001b[0m   run_dict[q_id]\u001b[38;5;241m.\u001b[39mappend({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdoc_id\u001b[39m\u001b[38;5;124m\"\u001b[39m:sample[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdoc_id\u001b[39m\u001b[38;5;124m\"\u001b[39m][i],\n\u001b[0;32m---> 19\u001b[0m                          \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscore\u001b[39m\u001b[38;5;124m\"\u001b[39m:\u001b[43mprob_relevant_pair\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m})\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "from collections import defaultdict\n",
        "\n",
        "run_dict = defaultdict(list) # q_id:[{\"doc_id\": doc_id, \"score\": prob}]\n",
        "\n",
        "for sample in tqdm(dataloader):\n",
        "  _inputs = sample[\"inputs\"].to(\"cuda\") # send inputs to gpu\n",
        "\n",
        "  # run inference\n",
        "  with torch.no_grad():\n",
        "    logits = model(**_inputs).logits # 0->value, 1->value\n",
        "\n",
        "    # based on the logits, we normalize to have a probabilistic distribution\n",
        "    # and we extract the probability of that query-doc pair being relevant!\n",
        "    prob_relevant_pair = torch.nn.functional.softmax(logits, dim=-1)[:,1] # [0-1]\n",
        "    # 32,\n",
        "\n",
        "  for i, q_id in enumerate(sample[\"id\"]):\n",
        "    run_dict[q_id].append({\"doc_id\":sample[\"doc_id\"][i],\n",
        "                           \"score\":prob_relevant_pair[i].item()})\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "# lest sort by the neural IR model prob and we have our reranked order!\n",
        "for q_id in run_dict:\n",
        "  run_dict[q_id].sort(key=lambda x:-x[\"score\"]) #prob\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[{'doc_id': '21719095', 'score': 0.0018358600791543722},\n",
              " {'doc_id': '12392636', 'score': 0.0016552183078601956},\n",
              " {'doc_id': '30569273', 'score': 0.0015651995781809092},\n",
              " {'doc_id': '10580413', 'score': 0.001373788807541132},\n",
              " {'doc_id': '25941654', 'score': 0.0012274904875084758},\n",
              " {'doc_id': '32153201', 'score': 0.0012172283604741096},\n",
              " {'doc_id': '30528099', 'score': 0.0011905573774129152},\n",
              " {'doc_id': '12951644', 'score': 0.0011223664041608572},\n",
              " {'doc_id': '31523950', 'score': 0.0011199505534023046},\n",
              " {'doc_id': '15793344', 'score': 0.0010940592037513852},\n",
              " {'doc_id': '17908555', 'score': 0.0010787309147417545},\n",
              " {'doc_id': '23322988', 'score': 0.0010592802427709103},\n",
              " {'doc_id': '15567323', 'score': 0.0010372999822720885},\n",
              " {'doc_id': '8518456', 'score': 0.0010154175106436014},\n",
              " {'doc_id': '20811157', 'score': 0.0010129488073289394},\n",
              " {'doc_id': '22997208', 'score': 0.0009966959478333592},\n",
              " {'doc_id': '17209507', 'score': 0.0009411661885678768},\n",
              " {'doc_id': '24517093', 'score': 0.0009240055806003511},\n",
              " {'doc_id': '34286946', 'score': 0.0009122012997977436},\n",
              " {'doc_id': '32031422', 'score': 0.0008906407165341079},\n",
              " {'doc_id': '34199021', 'score': 0.0008802275406196713},\n",
              " {'doc_id': '28926867', 'score': 0.0008739000768400729},\n",
              " {'doc_id': '20095914', 'score': 0.0008681645849719644},\n",
              " {'doc_id': '22186068', 'score': 0.0008241432369686663},\n",
              " {'doc_id': '12090547', 'score': 0.0008061874541454017},\n",
              " {'doc_id': '25107501', 'score': 0.0007968715508468449},\n",
              " {'doc_id': '33571602', 'score': 0.0007923504454083741},\n",
              " {'doc_id': '23423576', 'score': 0.0007792462129145861},\n",
              " {'doc_id': '3293948', 'score': 0.0007741403533145785},\n",
              " {'doc_id': '34560766', 'score': 0.000765060365665704},\n",
              " {'doc_id': '9868984', 'score': 0.0007601778488606215},\n",
              " {'doc_id': '32402065', 'score': 0.0007389350794255733},\n",
              " {'doc_id': '19729439', 'score': 0.000722133438102901},\n",
              " {'doc_id': '26666152', 'score': 0.0007150157471187413},\n",
              " {'doc_id': '26180580', 'score': 0.0006888345233164728},\n",
              " {'doc_id': '11919048', 'score': 0.0006811752682551742},\n",
              " {'doc_id': '23086558', 'score': 0.0006756374496035278},\n",
              " {'doc_id': '2079089', 'score': 0.0006507991347461939},\n",
              " {'doc_id': '31533907', 'score': 0.000650044356007129},\n",
              " {'doc_id': '16884582', 'score': 0.0006453478126786649},\n",
              " {'doc_id': '10863647', 'score': 0.0006387446774169803},\n",
              " {'doc_id': '33705532', 'score': 0.0006250511505641043},\n",
              " {'doc_id': '34307650', 'score': 0.0006249138386920094},\n",
              " {'doc_id': '34823737', 'score': 0.0006189337000250816},\n",
              " {'doc_id': '20398344', 'score': 0.0006129791727289557},\n",
              " {'doc_id': '11249772', 'score': 0.0006115378928370774},\n",
              " {'doc_id': '21128894', 'score': 0.0006080924649722874},\n",
              " {'doc_id': '22717959', 'score': 0.0006025350885465741},\n",
              " {'doc_id': '24059304', 'score': 0.0006010190700180829},\n",
              " {'doc_id': '3811707', 'score': 0.0005976404063403606},\n",
              " {'doc_id': '31119191', 'score': 0.0005801306688226759},\n",
              " {'doc_id': '20392114', 'score': 0.0005688393139280379},\n",
              " {'doc_id': '29669366', 'score': 0.0005625449703074992},\n",
              " {'doc_id': '22285932', 'score': 0.0005575749673880637},\n",
              " {'doc_id': '20484325', 'score': 0.0005539785488508642},\n",
              " {'doc_id': '12123481', 'score': 0.0005437183426693082},\n",
              " {'doc_id': '9119237', 'score': 0.0005408097058534622},\n",
              " {'doc_id': '16089357', 'score': 0.0005353914457373321},\n",
              " {'doc_id': '24689984', 'score': 0.0005335657042451203},\n",
              " {'doc_id': '27316092', 'score': 0.0005220640450716019},\n",
              " {'doc_id': '12939736', 'score': 0.0005136415711604059},\n",
              " {'doc_id': '23231526', 'score': 0.0005093977670185268},\n",
              " {'doc_id': '29776338', 'score': 0.0005034233909100294},\n",
              " {'doc_id': '26600218', 'score': 0.0005025031277909875},\n",
              " {'doc_id': '17893689', 'score': 0.0004973793984390795},\n",
              " {'doc_id': '11302779', 'score': 0.0004959820071235299},\n",
              " {'doc_id': '17935059', 'score': 0.0004942255327478051},\n",
              " {'doc_id': '22827639', 'score': 0.0004918899503536522},\n",
              " {'doc_id': '22968521', 'score': 0.000488986843265593},\n",
              " {'doc_id': '33206975', 'score': 0.0004796384309884161},\n",
              " {'doc_id': '15855346', 'score': 0.00047622251440770924},\n",
              " {'doc_id': '30830821', 'score': 0.00046134565491229296},\n",
              " {'doc_id': '23835333', 'score': 0.00045664882054552436},\n",
              " {'doc_id': '28759942', 'score': 0.000452940643299371},\n",
              " {'doc_id': '32192503', 'score': 0.0004457365139387548},\n",
              " {'doc_id': '28031898', 'score': 0.00044357814476825297},\n",
              " {'doc_id': '29068715', 'score': 0.00044120391248725355},\n",
              " {'doc_id': '33906426', 'score': 0.00043939327588304877},\n",
              " {'doc_id': '16114855', 'score': 0.00043779201223514974},\n",
              " {'doc_id': '23182614', 'score': 0.0004352760734036565},\n",
              " {'doc_id': '20820015', 'score': 0.0004349740920588374},\n",
              " {'doc_id': '9407262', 'score': 0.0004342664615251124},\n",
              " {'doc_id': '30228006', 'score': 0.00043359780102036893},\n",
              " {'doc_id': '9624524', 'score': 0.00043298437958583236},\n",
              " {'doc_id': '26262605', 'score': 0.00043042164179496467},\n",
              " {'doc_id': '11829450', 'score': 0.00042121714795939624},\n",
              " {'doc_id': '25422150', 'score': 0.0004186673031654209},\n",
              " {'doc_id': '28138827', 'score': 0.00040938513120636344},\n",
              " {'doc_id': '19646656', 'score': 0.0004086167027708143},\n",
              " {'doc_id': '9852983', 'score': 0.00039921386633068323},\n",
              " {'doc_id': '25260877', 'score': 0.00039385934360325336},\n",
              " {'doc_id': '29137448', 'score': 0.00039201113395392895},\n",
              " {'doc_id': '22655600', 'score': 0.0003864329191856086},\n",
              " {'doc_id': '11572100', 'score': 0.0003796282398980111},\n",
              " {'doc_id': '29757315', 'score': 0.00037348558544181287},\n",
              " {'doc_id': '23533381', 'score': 0.0003633135638665408},\n",
              " {'doc_id': '30283829', 'score': 0.00034782179864123464},\n",
              " {'doc_id': '22562111', 'score': 0.00034695147769525647},\n",
              " {'doc_id': '34845158', 'score': 0.00034390404471196234},\n",
              " {'doc_id': '29295245', 'score': 0.00030893951770849526}]"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "run_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "q = open(f\"files/eval/results/b075k12/BM25_{COLLECTION}.jsonl\",\"r\")\n",
        "new_run_dict = run_dict\n",
        "\n",
        "with open(f\"eval_results_{COLLECTION}.jsonl\", \"w\") as f:\n",
        "    for k, v in new_run_dict.items():\n",
        "        f.write(json.dumps({\"id\": k, \"documents\": [{\"id\": d[\"doc_id\"], \"score\": d[\"score\"]} for d in v], \"question\": json.loads(q.readline())[\"question\"]}) + \"\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'map@10': 0.12894736842105264, 'recall@10': 0.12894736842105264, 'ndcg@100': 1.0, 'mrr@10': 1.0}\n"
          ]
        }
      ],
      "source": [
        "from ranx import evaluate\n",
        "import json\n",
        "\n",
        "qrels = {}\n",
        "with open(f\"files/eval/results/b075k12/BM25_{COLLECTION}.jsonl\", \"r\") as f:\n",
        "    for line in f:\n",
        "        data = json.loads(line)\n",
        "        qrels[data[\"id\"]] = {doc[\"id\"]:1 for doc in data[\"documents\"]}\n",
        "\n",
        "n_run_dict = {}\n",
        "with open(f\"eval_results_{COLLECTION}.jsonl\", \"r\") as f:\n",
        "    for line in f:\n",
        "        data = json.loads(line)\n",
        "        n_run_dict[data[\"id\"]] = {doc[\"id\"]:doc[\"score\"] for doc in data[\"documents\"]}\n",
        "\n",
        "results = evaluate(qrels, run_dict, [\"map@10\", \"recall@10\",\"ndcg@100\",\"mrr@10\"])\n",
        "print(results)\n",
        "\n",
        "with open(f\"eval_{COLLECTION}_metrics.json\", \"w\") as f:\n",
        "    json.dump(results, f, indent=2)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyMt3kXZroGDapGW1yBVneR/",
      "collapsed_sections": [
        "SPE3498K1Nl7"
      ],
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
